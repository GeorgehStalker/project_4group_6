{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['patch.force_edgecolor'] = True\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                     NAME  GENDER                    EMAIL_ID  \\\n",
      "0           0        Johnny KerrThomas    Male     jacksonalan@example.com   \n",
      "1           1        Dwayne LarsenLara    Male        calvin80@example.com   \n",
      "2           2                      NaN    Male          qbrown@example.net   \n",
      "3           3  Russell SimmonsPhillips    Male  kimberlywagner@example.com   \n",
      "4           4     Jamie WilsonMartinez  Female     shaunbrooks@example.com   \n",
      "\n",
      "  IS_GLOGIN  FOLLOWER_COUNT  FOLLOWING_COUNT  DATASET_COUNT  CODE_COUNT  \\\n",
      "0     False            53.0             87.0            5.0         3.0   \n",
      "1      True            16.0             67.0            5.0         NaN   \n",
      "2      True            44.0             81.0            4.0        17.0   \n",
      "3      True            23.0            114.0            5.0        24.0   \n",
      "4     False            46.0            112.0            2.0        12.0   \n",
      "\n",
      "   DISCUSSION_COUNT  AVG_NB_READ_TIME_MIN REGISTRATION_IPV4  \\\n",
      "0             124.0                   NaN      81.88.75.170   \n",
      "1              26.0                 24.97               NaN   \n",
      "2             125.0                  7.75   159.202.103.178   \n",
      "3              67.0                 13.40     196.11.132.51   \n",
      "4              63.0                 24.83    159.196.199.20   \n",
      "\n",
      "  REGISTRATION_LOCATION  TOTAL_VOTES_GAVE_NB  TOTAL_VOTES_GAVE_DS  \\\n",
      "0             Argentina                 16.0                 10.0   \n",
      "1           New Zealand                 14.0                  5.0   \n",
      "2            Costa Rica                 16.0                  4.0   \n",
      "3                 Italy                 21.0                 10.0   \n",
      "4               Belgium                 10.0                  6.0   \n",
      "\n",
      "   TOTAL_VOTES_GAVE_DC  ISBOT  \n",
      "0                  3.0    NaN  \n",
      "1                  2.0    NaN  \n",
      "2                  0.0  False  \n",
      "3                  1.0  False  \n",
      "4                  2.0  False  \n"
     ]
    }
   ],
   "source": [
    "# Load your CSV file\n",
    "\n",
    "df = pd.read_csv('resources/kaggle_bot_accounts.csv')\n",
    "\n",
    "# Display the first few rows to check the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'NAME', 'GENDER', 'EMAIL_ID', 'IS_GLOGIN',\n",
      "       'FOLLOWER_COUNT', 'FOLLOWING_COUNT', 'DATASET_COUNT', 'CODE_COUNT',\n",
      "       'DISCUSSION_COUNT', 'AVG_NB_READ_TIME_MIN', 'REGISTRATION_IPV4',\n",
      "       'REGISTRATION_LOCATION', 'TOTAL_VOTES_GAVE_NB', 'TOTAL_VOTES_GAVE_DS',\n",
      "       'TOTAL_VOTES_GAVE_DC', 'ISBOT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check all column names\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in NAME: ['Johnny KerrThomas' 'Dwayne LarsenLara' nan ... 'Hector TerryLogan'\n",
      " 'William CollinsMartinez' 'Susan WilliamsJimenez']\n",
      "Unique values in GENDER: ['Male' 'Female' nan]\n",
      "Unique values in EMAIL_ID: ['jacksonalan@example.com' 'calvin80@example.com' 'qbrown@example.net' ...\n",
      " 'penningtondebra@example.net' 'kerrycastro@example.com'\n",
      " 'jonesmisty@example.net']\n",
      "Unique values in IS_GLOGIN: [False True nan]\n",
      "Unique values in FOLLOWER_COUNT: [53. 16. 44. 23. 46.  2. 50. 65. nan 70. 49.  0. 45. 55. 34. 19. 21.  3.\n",
      " 38. 57. 29. 10. 58. 61.  9. 64.  1. 48. 12. 32. 60. 27. 20. 18. 54. 37.\n",
      " 63. 17. 26. 39. 56. 41. 51. 31. 62.  4. 25. 69. 59.  8. 15. 66. 36. 22.\n",
      " 28.  6. 30. 24. 14. 67. 52. 11. 40. 13. 42. 43. 33. 68.  7. 35.  5. 47.]\n",
      "Unique values in FOLLOWING_COUNT: [ 87.  67.  81. 114. 112.   2.  36.   1.  25.  99.  44.  18.  14.  nan\n",
      "  15.  30.  62.  55.   3. 115.  84.   0. 120.  97.  17.  37.  68.  54.\n",
      "  75.  34. 107.  90.  88.  91.  86.  38.  53.  63.  51.  35.  29.  23.\n",
      "   4.  83.  73.  10.  72.  58.  78.  59.  60. 111.  80. 106.  76.  65.\n",
      "  13.  69.  32.  96. 113.  79.  77.   9. 109.  41. 117.  33.  43.  12.\n",
      "  89.   5.  19.  46. 119.  26.  64.  57.  11.  48. 116.  16.  45.  28.\n",
      "  52. 101.  49.  21.  82.  93.  39.  27.  92.   6.   7.   8.  98.  22.\n",
      " 118.  31.  24. 110.  71. 102.  85.  40. 104.  47.  61.  56.  42. 105.\n",
      "  70.  66. 100.  74.  95.  94. 103. 108.  20.  50.]\n",
      "Unique values in DATASET_COUNT: [ 5.  4.  2.  0.  1.  7.  3.  6. nan]\n",
      "Unique values in CODE_COUNT: [ 3. nan 17. 24. 12.  0. 16.  7. 19.  5. 23. 25. 21. 20. 18. 13.  6.  1.\n",
      " 15.  8. 14. 11.  4. 22. 10.  9.]\n",
      "Unique values in DISCUSSION_COUNT: [124.  26. 125.  67.  63.   0.  77.   6. 122.  93. 102.  75. 106.  58.\n",
      "  10. 104. 143. 138.   4.  95. 119. 127.  76.  90.   7. 144.  53.   1.\n",
      "  34.  73. 141.  11.   9.   2. 123.  74.  48.  29.  70. 126.  nan 107.\n",
      " 135.  86.  69. 117.  83.  80.  41.  42.   3.  92.  84.  31.  99.  55.\n",
      "  47.  13.  89.  30.  43.  28.   8.  71. 118.  54. 142.  59.  56.  81.\n",
      "  38.  79.  27. 137.  40. 128. 132. 103.  65.  36.  60.  72.  49. 139.\n",
      "  51.  35. 109.  98. 146.  64. 149.  66.  33.  96.  45.  91.  39.  37.\n",
      "  25. 147. 150.  61. 115.  88.  12. 120. 133. 111.  82.  94.  97.  85.\n",
      "  68.  52. 110. 130.   5.  50.  44. 101. 145. 131. 140. 114. 148. 105.\n",
      " 129. 112. 108. 136. 121. 113.  32.  62. 134.  78.  57.  46. 100.  87.\n",
      " 116.]\n",
      "Unique values in AVG_NB_READ_TIME_MIN: [  nan 24.97  7.75 ...  8.92 25.44 21.82]\n",
      "Unique values in REGISTRATION_IPV4: ['81.88.75.170' nan '159.202.103.178' ... '150.144.209.44'\n",
      " '146.121.179.46' '118.38.253.89']\n",
      "Unique values in REGISTRATION_LOCATION: ['Argentina' 'New Zealand' 'Costa Rica' 'Italy' 'Belgium'\n",
      " 'French Polynesia' 'South Georgia and the South Sandwich Islands'\n",
      " 'Antarctica (the territory South of 60 deg S)' nan 'Saint Lucia'\n",
      " 'Martinique' 'Aruba' 'Djibouti' 'Honduras' 'Mali' 'Burkina Faso'\n",
      " 'Equatorial Guinea' 'Estonia' 'Qatar' 'China' 'El Salvador' 'Gambia'\n",
      " 'Saudi Arabia' 'Sao Tome and Principe' 'Jordan' 'Portugal' 'Tonga'\n",
      " 'Greenland' 'Bolivia' 'Zimbabwe' 'Sudan' 'Mexico' 'Poland' 'South Africa'\n",
      " 'Spain' 'Bangladesh' 'Cuba' 'Iceland' 'Montserrat' 'Andorra' 'Mongolia'\n",
      " 'Cambodia' 'Niger' 'Netherlands' 'Saint Vincent and the Grenadines'\n",
      " 'Comoros' 'Zambia' 'Malaysia' 'Guinea' 'Japan' 'Kiribati' 'France'\n",
      " 'Guyana' 'Cook Islands' 'Bosnia and Herzegovina' 'Brunei Darussalam'\n",
      " 'Netherlands Antilles' 'Bulgaria' 'Bouvet Island (Bouvetoya)' 'Indonesia'\n",
      " 'Paraguay' 'Guadeloupe' 'Iran' 'Reunion' 'Saint Kitts and Nevis'\n",
      " 'Botswana' 'Oman' 'Anguilla' 'Latvia' 'Venezuela' 'Mauritania'\n",
      " 'Lithuania' 'Sierra Leone' 'Haiti' 'Senegal' 'Korea' 'Vanuatu' 'Nepal'\n",
      " 'Burundi' 'Uzbekistan' 'Singapore' 'Canada' 'Malawi' 'Dominica' 'Ukraine'\n",
      " 'Iraq' 'Solomon Islands' 'Macedonia' 'Somalia' 'Belize' 'Maldives'\n",
      " 'Serbia' 'Pakistan' 'Peru' 'Papua New Guinea' 'Vietnam' 'Ethiopia'\n",
      " 'Cyprus' 'Ireland' 'Jersey' 'Israel' 'India' 'Niue' 'Sri Lanka'\n",
      " \"Lao People's Democratic Republic\" \"Cote d'Ivoire\" 'Guam' 'Fiji'\n",
      " 'Nigeria' 'Grenada' 'New Caledonia' 'Saint Pierre and Miquelon' 'Benin'\n",
      " 'Kuwait' 'Bhutan' 'French Guiana' 'San Marino' 'Kazakhstan'\n",
      " 'American Samoa' 'Tuvalu' 'Turkmenistan' 'Marshall Islands' 'Brazil'\n",
      " 'Philippines' 'Macao' 'Croatia' 'British Virgin Islands' 'Lesotho'\n",
      " 'Pitcairn Islands' 'Algeria' 'Albania' 'Puerto Rico' 'Rwanda' 'Taiwan'\n",
      " 'Cameroon' 'Monaco' 'Bahamas' 'Angola' 'Norway' 'Antigua and Barbuda'\n",
      " 'Slovenia' 'Falkland Islands (Malvinas)' 'Guernsey' 'Nicaragua' 'Gabon'\n",
      " 'Russian Federation' 'Samoa' 'Northern Mariana Islands' 'Cayman Islands'\n",
      " 'Kenya' 'Palestinian Territory' 'Kyrgyz Republic' 'United Kingdom'\n",
      " 'Norfolk Island' 'Slovakia (Slovak Republic)' 'Hungary'\n",
      " 'British Indian Ocean Territory (Chagos Archipelago)' 'Mauritius'\n",
      " 'Uruguay' 'Tokelau' 'Colombia' 'Montenegro' 'Tajikistan' 'Romania'\n",
      " 'Liechtenstein' 'Morocco' 'Tunisia' 'Czech Republic' 'Dominican Republic'\n",
      " 'Malta' 'Armenia' 'United States Minor Outlying Islands' 'Namibia'\n",
      " 'Tanzania' 'Central African Republic' 'Yemen' 'Barbados' 'Swaziland'\n",
      " 'Svalbard & Jan Mayen Islands' 'Saint Martin' 'Gibraltar'\n",
      " 'Wallis and Futuna' 'Ghana' 'Mayotte' 'Mozambique' 'Moldova' 'Eritrea'\n",
      " 'Hong Kong' 'United States Virgin Islands' 'Guinea-Bissau' 'Luxembourg'\n",
      " 'Faroe Islands' 'Heard Island and McDonald Islands' 'Sweden' 'Cape Verde'\n",
      " 'Micronesia' 'Azerbaijan' 'Syrian Arab Republic' 'Palau'\n",
      " 'United States of America' 'Congo' 'Madagascar' 'Belarus' 'Togo'\n",
      " 'Saint Helena' 'United Arab Emirates' 'Bahrain' 'Ecuador' 'Isle of Man'\n",
      " 'Switzerland' 'Chad' 'Afghanistan' 'Denmark' 'Jamaica' 'Turkey'\n",
      " 'Suriname' 'Western Sahara' 'Chile' 'Nauru' 'Christmas Island' 'Thailand'\n",
      " 'Liberia' 'Georgia' 'Finland' 'Greece' 'Myanmar' 'Germany'\n",
      " 'Turks and Caicos Islands' 'Panama' 'Cocos (Keeling) Islands' 'Bermuda'\n",
      " 'Seychelles' 'Trinidad and Tobago' 'Egypt' 'Lebanon' 'Uganda'\n",
      " 'French Southern Territories' 'Holy See (Vatican City State)'\n",
      " 'Timor-Leste' 'Guatemala' 'Libyan Arab Jamahiriya' 'Austria'\n",
      " 'Saint Barthelemy' 'Australia']\n",
      "Unique values in TOTAL_VOTES_GAVE_NB: [16. 14. 21. 10. 18. nan 24. 23. 13. 25. 12. 17. 19. 11. 15. 22. 20.]\n",
      "Unique values in TOTAL_VOTES_GAVE_DS: [10.  5.  4.  6.  9.  3.  7.  8. nan]\n",
      "Unique values in TOTAL_VOTES_GAVE_DC: [ 3.  2.  0.  1. nan]\n",
      "Unique values in ISBOT: [nan False True]\n"
     ]
    }
   ],
   "source": [
    "# Get unique values for each column separately\n",
    "name_unique = df['NAME'].unique()\n",
    "gender_unique = df['GENDER'].unique()\n",
    "email_unique = df['EMAIL_ID'].unique()\n",
    "is_glogin_unique = df['IS_GLOGIN'].unique()\n",
    "follower_count_unique = df['FOLLOWER_COUNT'].unique()\n",
    "following_count_unique = df['FOLLOWING_COUNT'].unique()\n",
    "dataset_count_unique = df['DATASET_COUNT'].unique()\n",
    "code_count_unique = df['CODE_COUNT'].unique()\n",
    "discussion_count_unique = df['DISCUSSION_COUNT'].unique()\n",
    "avg_nb_read_time_min_unique = df['AVG_NB_READ_TIME_MIN'].unique()\n",
    "registration_ipv4_unique = df['REGISTRATION_IPV4'].unique()\n",
    "registration_location_unique = df['REGISTRATION_LOCATION'].unique()\n",
    "total_votes_gave_nb_unique = df['TOTAL_VOTES_GAVE_NB'].unique()\n",
    "total_votes_gave_ds_unique = df['TOTAL_VOTES_GAVE_DS'].unique()\n",
    "total_votes_gave_dc_unique = df['TOTAL_VOTES_GAVE_DC'].unique()\n",
    "isbot_unique = df['ISBOT'].unique()\n",
    "\n",
    "# Print unique values for each column\n",
    "print('Unique values in NAME:', name_unique)\n",
    "print('Unique values in GENDER:', gender_unique)\n",
    "print('Unique values in EMAIL_ID:', email_unique)\n",
    "print('Unique values in IS_GLOGIN:', is_glogin_unique)\n",
    "print('Unique values in FOLLOWER_COUNT:', follower_count_unique)\n",
    "print('Unique values in FOLLOWING_COUNT:', following_count_unique)\n",
    "print('Unique values in DATASET_COUNT:', dataset_count_unique)\n",
    "print('Unique values in CODE_COUNT:', code_count_unique)\n",
    "print('Unique values in DISCUSSION_COUNT:', discussion_count_unique)\n",
    "print('Unique values in AVG_NB_READ_TIME_MIN:', avg_nb_read_time_min_unique)\n",
    "print('Unique values in REGISTRATION_IPV4:', registration_ipv4_unique)\n",
    "print('Unique values in REGISTRATION_LOCATION:', registration_location_unique)\n",
    "print('Unique values in TOTAL_VOTES_GAVE_NB:', total_votes_gave_nb_unique)\n",
    "print('Unique values in TOTAL_VOTES_GAVE_DS:', total_votes_gave_ds_unique)\n",
    "print('Unique values in TOTAL_VOTES_GAVE_DC:', total_votes_gave_dc_unique)\n",
    "print('Unique values in ISBOT:', isbot_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1321188 entries, 0 to 1321187\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1321188 non-null  int64  \n",
      " 1   NAME                   1243024 non-null  object \n",
      " 2   GENDER                 1243309 non-null  object \n",
      " 3   EMAIL_ID               1243374 non-null  object \n",
      " 4   IS_GLOGIN              1243272 non-null  object \n",
      " 5   FOLLOWER_COUNT         1243476 non-null  float64\n",
      " 6   FOLLOWING_COUNT        1242743 non-null  float64\n",
      " 7   DATASET_COUNT          1242621 non-null  float64\n",
      " 8   CODE_COUNT             1243262 non-null  float64\n",
      " 9   DISCUSSION_COUNT       1243466 non-null  float64\n",
      " 10  AVG_NB_READ_TIME_MIN   1242872 non-null  float64\n",
      " 11  REGISTRATION_IPV4      1242859 non-null  object \n",
      " 12  REGISTRATION_LOCATION  1242898 non-null  object \n",
      " 13  TOTAL_VOTES_GAVE_NB    1243483 non-null  float64\n",
      " 14  TOTAL_VOTES_GAVE_DS    1243254 non-null  float64\n",
      " 15  TOTAL_VOTES_GAVE_DC    1243158 non-null  float64\n",
      " 16  ISBOT                  1242688 non-null  object \n",
      "dtypes: float64(9), int64(1), object(7)\n",
      "memory usage: 171.4+ MB\n",
      "None\n",
      "\n",
      "Summary statistics (before):\n",
      "          Unnamed: 0              NAME   GENDER            EMAIL_ID IS_GLOGIN  \\\n",
      "count   1.321188e+06           1243024  1243309             1243374   1243272   \n",
      "unique           NaN           1199433        2              603013         2   \n",
      "top              NaN  David SmithSmith     Male  csmith@example.org     False   \n",
      "freq             NaN                17   932220                 117    788359   \n",
      "mean    6.605935e+05               NaN      NaN                 NaN       NaN   \n",
      "std     3.813943e+05               NaN      NaN                 NaN       NaN   \n",
      "min     0.000000e+00               NaN      NaN                 NaN       NaN   \n",
      "25%     3.302968e+05               NaN      NaN                 NaN       NaN   \n",
      "50%     6.605935e+05               NaN      NaN                 NaN       NaN   \n",
      "75%     9.908902e+05               NaN      NaN                 NaN       NaN   \n",
      "max     1.321187e+06               NaN      NaN                 NaN       NaN   \n",
      "\n",
      "        FOLLOWER_COUNT  FOLLOWING_COUNT  DATASET_COUNT    CODE_COUNT  \\\n",
      "count     1.243476e+06     1.242743e+06   1.242621e+06  1.243262e+06   \n",
      "unique             NaN              NaN            NaN           NaN   \n",
      "top                NaN              NaN            NaN           NaN   \n",
      "freq               NaN              NaN            NaN           NaN   \n",
      "mean      2.698273e+01     4.505091e+01   2.562564e+00  1.038450e+01   \n",
      "std       2.300504e+01     3.947716e+01   2.499882e+00  8.248055e+00   \n",
      "min       0.000000e+00     0.000000e+00   0.000000e+00  0.000000e+00   \n",
      "25%       2.000000e+00     3.000000e+00   0.000000e+00  1.000000e+00   \n",
      "50%       2.400000e+01     3.900000e+01   2.000000e+00  1.000000e+01   \n",
      "75%       4.700000e+01     8.000000e+01   5.000000e+00  1.800000e+01   \n",
      "max       7.000000e+01     1.200000e+02   7.000000e+00  2.500000e+01   \n",
      "\n",
      "        DISCUSSION_COUNT  AVG_NB_READ_TIME_MIN REGISTRATION_IPV4  \\\n",
      "count       1.243466e+06          1.242872e+06           1242859   \n",
      "unique               NaN                   NaN           1242579   \n",
      "top                  NaN                   NaN    195.32.175.129   \n",
      "freq                 NaN                   NaN                 2   \n",
      "mean        6.584244e+01          1.274225e+01               NaN   \n",
      "std         4.754315e+01          9.564920e+00               NaN   \n",
      "min         0.000000e+00          0.000000e+00               NaN   \n",
      "25%         1.300000e+01          1.870000e+00               NaN   \n",
      "50%         6.500000e+01          1.229000e+01               NaN   \n",
      "75%         1.080000e+02          2.119000e+01               NaN   \n",
      "max         1.500000e+02          2.999000e+01               NaN   \n",
      "\n",
      "       REGISTRATION_LOCATION  TOTAL_VOTES_GAVE_NB  TOTAL_VOTES_GAVE_DS  \\\n",
      "count                1242898         1.243483e+06         1.243254e+06   \n",
      "unique                   243                  NaN                  NaN   \n",
      "top                    Korea                  NaN                  NaN   \n",
      "freq                   10128                  NaN                  NaN   \n",
      "mean                     NaN         1.750656e+01         6.501007e+00   \n",
      "std                      NaN         4.611783e+00         2.290951e+00   \n",
      "min                      NaN         1.000000e+01         3.000000e+00   \n",
      "25%                      NaN         1.400000e+01         5.000000e+00   \n",
      "50%                      NaN         1.800000e+01         7.000000e+00   \n",
      "75%                      NaN         2.200000e+01         9.000000e+00   \n",
      "max                      NaN         2.500000e+01         1.000000e+01   \n",
      "\n",
      "        TOTAL_VOTES_GAVE_DC    ISBOT  \n",
      "count          1.243158e+06  1242688  \n",
      "unique                  NaN        2  \n",
      "top                     NaN    False  \n",
      "freq                    NaN   909794  \n",
      "mean           1.500373e+00      NaN  \n",
      "std            1.118067e+00      NaN  \n",
      "min            0.000000e+00      NaN  \n",
      "25%            1.000000e+00      NaN  \n",
      "50%            2.000000e+00      NaN  \n",
      "75%            3.000000e+00      NaN  \n",
      "max            3.000000e+00      NaN  \n",
      "\n",
      "After Cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1321188 entries, 0 to 1321187\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   NAME                   1321188 non-null  object \n",
      " 1   GENDER                 1321188 non-null  object \n",
      " 2   EMAIL_ID               1321188 non-null  object \n",
      " 3   IS_GLOGIN              1321188 non-null  bool   \n",
      " 4   FOLLOWER_COUNT         1321188 non-null  int32  \n",
      " 5   FOLLOWING_COUNT        1321188 non-null  int32  \n",
      " 6   DATASET_COUNT          1321188 non-null  float64\n",
      " 7   CODE_COUNT             1321188 non-null  float64\n",
      " 8   DISCUSSION_COUNT       1321188 non-null  float64\n",
      " 9   AVG_NB_READ_TIME_MIN   1321188 non-null  float64\n",
      " 10  REGISTRATION_IPV4      1242859 non-null  object \n",
      " 11  REGISTRATION_LOCATION  1242898 non-null  object \n",
      " 12  TOTAL_VOTES_GAVE_NB    1321188 non-null  float64\n",
      " 13  TOTAL_VOTES_GAVE_DS    1321188 non-null  float64\n",
      " 14  TOTAL_VOTES_GAVE_DC    1321188 non-null  float64\n",
      " 15  ISBOT                  1242688 non-null  object \n",
      "dtypes: bool(1), float64(7), int32(2), object(6)\n",
      "memory usage: 142.4+ MB\n",
      "None\n",
      "\n",
      "Summary statistics (after):\n",
      "           NAME   GENDER             EMAIL_ID IS_GLOGIN  FOLLOWER_COUNT  \\\n",
      "count   1321188  1321188              1321188   1321188    1.321188e+06   \n",
      "unique  1199434        3               603014         2             NaN   \n",
      "top     Unknown     Male  unknown@example.com     False             NaN   \n",
      "freq      78164   932220                77814    866275             NaN   \n",
      "mean        NaN      NaN                  NaN       NaN    2.692493e+01   \n",
      "std         NaN      NaN                  NaN       NaN    2.231941e+01   \n",
      "min         NaN      NaN                  NaN       NaN    0.000000e+00   \n",
      "25%         NaN      NaN                  NaN       NaN    2.000000e+00   \n",
      "50%         NaN      NaN                  NaN       NaN    2.600000e+01   \n",
      "75%         NaN      NaN                  NaN       NaN    4.600000e+01   \n",
      "max         NaN      NaN                  NaN       NaN    7.000000e+01   \n",
      "\n",
      "        FOLLOWING_COUNT  DATASET_COUNT    CODE_COUNT  DISCUSSION_COUNT  \\\n",
      "count      1.321188e+06   1.321188e+06  1.321188e+06      1.321188e+06   \n",
      "unique              NaN            NaN           NaN               NaN   \n",
      "top                 NaN            NaN           NaN               NaN   \n",
      "freq                NaN            NaN           NaN               NaN   \n",
      "mean       4.504789e+01   2.410176e+00  9.772007e+00      6.196911e+01   \n",
      "std        3.828725e+01   2.499011e+00  8.366790e+00      4.865602e+01   \n",
      "min        0.000000e+00   0.000000e+00  0.000000e+00      0.000000e+00   \n",
      "25%        3.000000e+00   0.000000e+00  1.000000e+00      1.000000e+01   \n",
      "50%        4.400000e+01   2.000000e+00  9.000000e+00      5.900000e+01   \n",
      "75%        7.700000e+01   5.000000e+00  1.700000e+01      1.050000e+02   \n",
      "max        1.200000e+02   7.000000e+00  2.500000e+01      1.500000e+02   \n",
      "\n",
      "        AVG_NB_READ_TIME_MIN REGISTRATION_IPV4 REGISTRATION_LOCATION  \\\n",
      "count           1.321188e+06           1242859               1242898   \n",
      "unique                   NaN           1242579                   243   \n",
      "top                      NaN    195.32.175.129                 Korea   \n",
      "freq                     NaN                 2                 10128   \n",
      "mean            1.274225e+01               NaN                   NaN   \n",
      "std             9.277100e+00               NaN                   NaN   \n",
      "min             0.000000e+00               NaN                   NaN   \n",
      "25%             1.980000e+00               NaN                   NaN   \n",
      "50%             1.274225e+01               NaN                   NaN   \n",
      "75%             2.059000e+01               NaN                   NaN   \n",
      "max             2.999000e+01               NaN                   NaN   \n",
      "\n",
      "        TOTAL_VOTES_GAVE_NB  TOTAL_VOTES_GAVE_DS  TOTAL_VOTES_GAVE_DC    ISBOT  \n",
      "count          1.321188e+06         1.321188e+06         1.321188e+06  1242688  \n",
      "unique                  NaN                  NaN                  NaN        2  \n",
      "top                     NaN                  NaN                  NaN    False  \n",
      "freq                    NaN                  NaN                  NaN   909794  \n",
      "mean           1.647692e+01         6.117527e+00         1.411760e+00      NaN  \n",
      "std            6.081361e+00         2.699040e+00         1.140764e+00      NaN  \n",
      "min            0.000000e+00         0.000000e+00         0.000000e+00      NaN  \n",
      "25%            1.300000e+01         4.000000e+00         0.000000e+00      NaN  \n",
      "50%            1.700000e+01         6.000000e+00         1.000000e+00      NaN  \n",
      "75%            2.100000e+01         8.000000e+00         2.000000e+00      NaN  \n",
      "max            2.500000e+01         1.000000e+01         3.000000e+00      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Step 0: Before cleaning - Print basic info and summary\n",
    "print(\"Before Cleaning:\")\n",
    "print(df.info())  # Info about columns, data types, and non-null counts\n",
    "print(\"\\nSummary statistics (before):\")\n",
    "print(df.describe(include='all'))  # Summary statistics before cleaning\n",
    "\n",
    "# Step 1: Remove unnecessary columns\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "# For categorical columns\n",
    "df['NAME'] = df['NAME'].fillna('Unknown')\n",
    "df['GENDER'] = df['GENDER'].fillna('Unknown')\n",
    "df['EMAIL_ID'] = df['EMAIL_ID'].fillna('unknown@example.com')\n",
    "df['IS_GLOGIN'] = df['IS_GLOGIN'].fillna(False)\n",
    "\n",
    "# For numerical columns (e.g., filling NaNs with mean)\n",
    "df['FOLLOWER_COUNT'] = df['FOLLOWER_COUNT'].fillna(df['FOLLOWER_COUNT'].mean())\n",
    "df['FOLLOWING_COUNT'] = df['FOLLOWING_COUNT'].fillna(df['FOLLOWING_COUNT'].mean())\n",
    "df['DATASET_COUNT'] = df['DATASET_COUNT'].fillna(0)  # Assuming 0 is a reasonable fill\n",
    "df['CODE_COUNT'] = df['CODE_COUNT'].fillna(0)\n",
    "df['DISCUSSION_COUNT'] = df['DISCUSSION_COUNT'].fillna(0)\n",
    "df['AVG_NB_READ_TIME_MIN'] = df['AVG_NB_READ_TIME_MIN'].fillna(df['AVG_NB_READ_TIME_MIN'].mean())\n",
    "df['TOTAL_VOTES_GAVE_NB'] = df['TOTAL_VOTES_GAVE_NB'].fillna(0)\n",
    "df['TOTAL_VOTES_GAVE_DS'] = df['TOTAL_VOTES_GAVE_DS'].fillna(0)\n",
    "df['TOTAL_VOTES_GAVE_DC'] = df['TOTAL_VOTES_GAVE_DC'].fillna(0)\n",
    "\n",
    "# Step 3: Standardize categorical values (if needed)\n",
    "df['GENDER'] = df['GENDER'].str.title()  # Capitalize gender values\n",
    "\n",
    "# Step 4: Convert data types\n",
    "df['FOLLOWER_COUNT'] = df['FOLLOWER_COUNT'].astype(int)\n",
    "df['FOLLOWING_COUNT'] = df['FOLLOWING_COUNT'].astype(int)\n",
    "\n",
    "# Step 5: Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Step 6: After cleaning - Print basic info and summary\n",
    "print(\"\\nAfter Cleaning:\")\n",
    "print(df.info())  # Info about columns, data types, and non-null counts\n",
    "print(\"\\nSummary statistics (after):\")\n",
    "print(df.describe(include='all'))  # Summary statistics after cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1321188 entries, 0 to 1321187\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count    Dtype \n",
      "---  ------                 --------------    ----- \n",
      " 0   NAME                   1321188 non-null  object\n",
      " 1   GENDER                 1321188 non-null  object\n",
      " 2   EMAIL_ID               1321188 non-null  object\n",
      " 3   IS_GLOGIN              1321188 non-null  bool  \n",
      " 4   FOLLOWER_COUNT         1321188 non-null  int32 \n",
      " 5   FOLLOWING_COUNT        1321188 non-null  int32 \n",
      " 6   DATASET_COUNT          1321188 non-null  int32 \n",
      " 7   CODE_COUNT             1321188 non-null  int32 \n",
      " 8   DISCUSSION_COUNT       1321188 non-null  int32 \n",
      " 9   AVG_NB_READ_TIME_MIN   1321188 non-null  int32 \n",
      " 10  REGISTRATION_IPV4      1321188 non-null  object\n",
      " 11  REGISTRATION_LOCATION  1321188 non-null  object\n",
      " 12  TOTAL_VOTES_GAVE_NB    1321188 non-null  int32 \n",
      " 13  TOTAL_VOTES_GAVE_DS    1321188 non-null  int32 \n",
      " 14  TOTAL_VOTES_GAVE_DC    1321188 non-null  int32 \n",
      " 15  ISBOT                  1321188 non-null  object\n",
      "dtypes: bool(1), int32(9), object(6)\n",
      "memory usage: 107.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values for REGISTRATION_IPV4 and REGISTRATION_LOCATION\n",
    "df['REGISTRATION_IPV4'] = df['REGISTRATION_IPV4'].fillna('Unknown')\n",
    "df['REGISTRATION_LOCATION'] = df['REGISTRATION_LOCATION'].fillna('Unknown')\n",
    "\n",
    "# Handle missing values for ISBOT\n",
    "df['ISBOT'] = df['ISBOT'].fillna('Unknown')  # Or you can set to False if that's more appropriate\n",
    "\n",
    "# Optional: Convert float columns to int if applicable\n",
    "float_columns = ['DATASET_COUNT', 'CODE_COUNT', 'DISCUSSION_COUNT', 'AVG_NB_READ_TIME_MIN',\n",
    "                 'TOTAL_VOTES_GAVE_NB', 'TOTAL_VOTES_GAVE_DS', 'TOTAL_VOTES_GAVE_DC']\n",
    "\n",
    "for col in float_columns:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bots: 332894\n",
      "Number of non-bots: 909794\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values in the ISBOT column\n",
    "data_cleaned = df.dropna(subset=['ISBOT'])\n",
    "\n",
    "# Now you can separate bots and non-bots\n",
    "bots = data_cleaned[data_cleaned['ISBOT'] == True]\n",
    "nonbots = data_cleaned[data_cleaned['ISBOT'] == False]\n",
    "# Optional: print the counts\n",
    "print(\"Number of bots:\", bots.shape[0])\n",
    "print(\"Number of non-bots:\", nonbots.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unknown' False True]\n"
     ]
    }
   ],
   "source": [
    "# Display the unique values in the ISBOT column\n",
    "print(data_cleaned['ISBOT'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBOT\n",
      "False      909794\n",
      "True       332894\n",
      "Unknown     78500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the count of each value in the ISBOT column\n",
    "print(data_cleaned['ISBOT'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where ISBOT is 'Unknown'\n",
    "data_cleaned = data_cleaned[data_cleaned['ISBOT'] != 'Unknown']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ISBOT to binary (1 for True, 0 for False)\n",
    "data_cleaned['ISBOT_BINARY'] = data_cleaned['ISBOT'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBOT\n",
      "False    909794\n",
      "True     332894\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the count of each value in the ISBOT column\n",
    "print(data_cleaned['ISBOT'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ISBOT  ISBOT_BINARY\n",
      "2  False             1\n",
      "3  False             1\n",
      "4  False             1\n",
      "5   True             0\n",
      "6  False             1\n"
     ]
    }
   ],
   "source": [
    "# Map True to 0 and False to 1 in the ISBOT column\n",
    "data_cleaned['ISBOT_BINARY'] = data_cleaned['ISBOT'].map({True: 0, False: 1})\n",
    "\n",
    "# Verify the changes\n",
    "print(data_cleaned[['ISBOT', 'ISBOT_BINARY']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data_cleaned' is your final DataFrame after cleaning\n",
    "data_cleaned.to_csv('cleaned_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_cleaned\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_cleaned' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
